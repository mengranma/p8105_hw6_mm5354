---
title: "p8105_hw6_mm5354"
author: "Mengran Ma"
date: "2018/11/15"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(purrr)
library(modelr)
library(broom)
library("leaps")
```
#Problem 1

###Create a city_state variable (e.g. “Baltimore, MD”), and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix, AZ; and Kansas City, MO – these don’t report victim race. Also omit Tulsa, AL – this is a data entry mistake. Modifiy victim_race to have categories white and non-white, with white as the reference category. Be sure that victim_age is numeric.
```{r Problem1_import_data}
tidy_data = 
  read_csv("/Users/nadongma/Desktop/p8105_hw6_mm5354/homicide_data.csv") %>% 
  janitor::clean_names() %>%
  unite(city_state, city, state, sep = ", ", remove = FALSE) %>%
  mutate(solved_or_not = 1) %>%
  mutate(solved_or_not = 0 * (disposition != "Closed by arrest") + 1 * (disposition == "Closed by arrest")) %>%
  filter(city_state != "Dallas, TX" & city_state != "Phoenix, AZ" & city_state != "Kansas City, MO" & city_state != "Tulsa, AL") %>%
  filter(victim_race != "Unknown") %>% 
  mutate(victim_race = 1 * (victim_race != "White") + 0 * (victim_race == "White")) %>% 
  mutate(victim_age = as.numeric(victim_age))
```

###For the city of Baltimore, MD, use the glm function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race (as just defined) as predictors. Save the output of glm as an R object; apply the broom::tidy to this object; and obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed.
```{r logistic_regression}
logistic_regression = tidy_data %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(solved_or_not ~ victim_age + victim_sex + victim_race, data = ., family = binomial()) %>%
  broom::tidy() %>%
  mutate(OR = exp(estimate),
         lower_bound = exp(estimate - std.error*1.96),
         upper_bound = exp(estimate + std.error*1.96)) %>%
  select(term, log_OR = estimate, lower_bound, upper_bound, OR, p.value) %>% 
  knitr::kable(digits = 3)
logistic_regression
```


###Now run glm for each of the cities in your dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing non-white victims to white victims. Do this within a “tidy” pipeline, making use of purrr::map, list columns, and unnest as necessary to create a dataframe with estimated ORs and CIs for each city.
```{r regression}
city_nest = tidy_data %>% 
  group_by(city_state) %>% 
  nest() %>%
  mutate(models = map(data, ~glm(solved_or_not ~ victim_age + victim_race + victim_sex, data = ., family = binomial())),
         models = map(models, broom::tidy)) %>% 
  select(-data) %>% 
  unnest() %>%
  mutate(OR = exp(estimate),
         lower_bound = exp(estimate - std.error*1.96),
         upper_bound = exp(estimate + std.error*1.96)) %>%
  select(city_state, term, log_OR = estimate, OR, lower_bound, upper_bound, p.value)
city_nest %>%
  filter(term == "victim_race") %>% 
  knitr::kable(digits = 3)
```

```{r plot, fig.height=6, dpi=300}
city_nest %>% 
  filter(term == "victim_race") %>% 
  mutate(city_state = fct_reorder(city_state, OR)) %>% 
  ggplot(aes(x = city_state, y = OR, color = city_state)) +
  geom_point() +
  geom_errorbar(aes(ymin = lower_bound , ymax = upper_bound), width = 0.25) +
  labs(
      title = "Proportion estimates and CIs for each city",
      x = "City",
      y = "Estimate"
      ) +
  theme(axis.text.x = element_text(angle = 90, size = 6)) +
  theme(legend.position = "none")
```

#Problem 2


Read and tidy data.
```{r Problem2_import_data}
tidy_data_P2 = 
  read_csv("/Users/nadongma/Desktop/p8105_hw6_mm5354/birthweight.csv") %>% 
  janitor::clean_names() %>%
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace)) %>% 
  mutate(babysex_recode = 1) %>%
  mutate(babysex_recode = 0 * (babysex != 1) + 1 * (babysex == 1))
```



###Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. Describe your modeling process and show a plot of model residuals against fitted values.
```{r Problem2_my_regression, fig.height=6, dpi=300}
#fit = lm(bwt ~ bhead + blength + wtgain, data = tidy_data_P2)

tidy_data_P2 <- tidy_data_P2 %>% 
  select(bwt, babysex, bhead, blength, gaweeks, malform, 
         delwt, menarche, mheight, momage, mrace, parity, pnumlbw, pnumsga, ppbmi, ppwt, smoken, wtgain,
         everything())

fit <- lm(bwt ~ ., data = tidy_data_P2)
step(fit, direction = 'backward')


best <- function(model, ...) 
{
  subsets <- regsubsets(formula(model), model.frame(model), ...)
  subsets <- with(summary(subsets),
                  cbind(p = as.numeric(rownames(which)), which, rss, rsq, adjr2, cp, bic))
  
  return(subsets)
}   

# Select the 'best' model of all subsets for 3-predictor model
round(best(fit, nbest = 1), 3)


# Summary of models for each size (one model per size)
b<-regsubsets(bwt ~ ., data = tidy_data_P2)
   (rs<-summary(b))

# Plots of Cp and Adj-R2 as functions of parameters
par(mar=c(4,4,1,1))
par(mfrow=c(1,2))

plot(2:10, rs$cp, xlab="No of parameters", ylab="Cp Statistic")
abline(0,1)

plot(2:10, rs$adjr2, xlab="No of parameters", ylab="Adj R2")


tidy_data_P2 = modelr::add_residuals(tidy_data_P2, fit)
tidy_data_P2 = modelr::add_predictions(tidy_data_P2, fit)
tidy_data_P2

tidy_data_P2 %>% 
  ggplot(aes(x = pred, y = resid))+geom_point()

fit2 = lm(bwt ~ blength + gaweeks, data = tidy_data_P2)
fit2
fit3 = lm(bwt ~ bhead + blength + babysex + bhead*babysex + bhead*blength + blength*babysex, data = tidy_data_P2)
fit3
```

My data-driven model-building process: Here I use Model Building/Variable Selection methodology to explore various models. According to the **Plots of Cp and Adj-R2 as functions of parameters**, the **adjusted R^2** (coefficient of determination: describes how good the model fits) does not change that much after having **5** predictors' model. Also **Cp value** does not change that much after obtaining **5** predictors' model, for which this model is containing: 'baby’s birth weight (grams)' (Y) vs. 'bhead', 'blength', 'gaweeks', 'delwt',' mrace' (Xs). Therefore, I would use this model to address investigator’s objective, since the investigator is mainly interested in understanding the effects of several variables on a child’s birthweight.

###Compare my model to two others
### *One using length at birth and gestational age as predictors (main effects only)
### *One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
###Make this comparison in terms of the cross-validated prediction error.
```{r Problem2_cross_validation, fig.height=6, dpi=300}
cv_P2 = tidy_data_P2 %>%
  crossv_mc(n = 100)

print(cv_P2)

cv_models = cv_P2 %>%
  mutate(my_model1 = map(train, ~lm(bwt ~ bhead + blength + gaweeks + delwt + mrace, data = .)),
         model2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .)),
         model3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*babysex + bhead*blength + blength*babysex + bhead*babysex*blength, data = .)))

print(cv_models)

rmse_cv = cv_models %>%
  mutate(rmse_models_1 = map2_dbl(my_model1, test, ~rmse(.x, .y)),
         rmse_models_2 = map2_dbl(model2, test, ~rmse(.x, .y)),
         rmse_models_3 = map2_dbl(model3, test, ~rmse(.x, .y)))

rmse_cv %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()

```

My Comment: based on the RMSE criterion, the model that I chose (model #1) and model #3 (One using head circumference, length, sex, and all interactions (including the three-way interaction)) all have pretty low mean rmses and low error variances comparing to model #2 (One using length at birth and gestational age as predictors (main effects only)). Moreover, based on the RMSE criterion, the model I chose have the least mean rmse and least error variance across all three models.